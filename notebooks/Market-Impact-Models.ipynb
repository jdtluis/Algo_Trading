{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def perf_impact(leverage, turnover , trading_days, txn_cost_bps):\n",
    "    p = leverage *  turnover * trading_days * txn_cost_bps/10000.\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(perf_impact(leverage=2, turnover=0.4, trading_days=252, txn_cost_bps=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,1,101)\n",
    "risk = np.cos(x*np.pi)\n",
    "impact = np.cos(x* np.pi+ np.pi)\n",
    "\n",
    "fig,ax = plt.subplots(1)\n",
    "# Make your plot, set your axes labels\n",
    "ax.plot(x,risk)\n",
    "ax.plot(x,impact)\n",
    "ax.set_ylabel('Transaction Cost in bps', fontsize=15)\n",
    "ax.set_xlabel('Order Interval', fontsize=15)\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "ax.grid(False)\n",
    "ax.text(0.09, -0.6, 'Timing Risk', fontsize=15, fontname=\"serif\")\n",
    "ax.text(0.08, 0.6, 'Market Impact', fontsize=15, fontname=\"serif\")\n",
    "plt.title('Timing Risk vs Market Impact Affect on Transaction Cost', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from quantrocket.master import get_securities\n",
    "from quantrocket import get_prices\n",
    "\n",
    "securities = get_securities(symbols='AAPL', vendors='usstock')\n",
    "AAPL = securities.index[0]\n",
    "data = get_prices('usstock-free-1min', sids=AAPL, data_frequency='minute', start_date='2016-01-01', end_date='2016-07-01', fields='Volume')\n",
    "dat = data.loc['Volume'][AAPL]\n",
    "\n",
    "# Combine separate Date and Time in index into datetime\n",
    "dat.index = pd.to_datetime(dat.index.get_level_values('Date').astype(str) + ' ' + dat.index.get_level_values('Time'))\n",
    "\n",
    "plt.subplot(211)\n",
    "dat['2016-04-14'].plot(title='Intraday Volume Profile') # intraday volume profile plot \n",
    "plt.subplot(212)\n",
    "(dat['2016-04-14'].resample('10t', closed='right').sum()/\\\n",
    "     dat['2016-04-14'].sum()).plot(); # percent volume plot\n",
    "plt.title('Intraday Volume Profile, % Total Day');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dat) # Apple minutely volume data\n",
    "\n",
    "df.columns = ['interval_vlm'] \n",
    "\n",
    "df_daysum = df.resample('d').sum() # take sum of each day \n",
    "df_daysum.columns = ['day_vlm']\n",
    "df_daysum['day'] = df_daysum.index.date # add date index as column\n",
    "\n",
    "df['min_of_day']=(df.index.hour-9)*60 + (df.index.minute-30) # calculate minutes from open\n",
    "df['time']=df.index.time # add time index as column\n",
    "\n",
    "conversion = {'interval_vlm':'sum', 'min_of_day':'last', 'time':'last'}\n",
    "df = df.resample('10t', closed='right').apply(conversion) # apply conversions to columns at 10 min intervals\n",
    "df['day'] = df.index.date\n",
    "\n",
    "df = df.merge(df_daysum, how='left', on='day') # merge df and df_daysum dataframes\n",
    "df['interval_pct'] = df['interval_vlm'] / df['day_vlm'] # calculate percent of days volume for each row\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.min_of_day, df.interval_pct)\n",
    "plt.xlim(0,400)\n",
    "plt.xlabel('Time from the Open (minutes)')\n",
    "plt.ylabel('Percent Days Volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(df.min_of_day)\n",
    "grouped = df.groupby(df.time) # group by 10 minute interval times\n",
    "m = grouped.median()  # get median values of groupby\n",
    "x = m.index\n",
    "y = m['interval_pct']\n",
    "\n",
    "ax1 = (100*y).plot(kind='bar', alpha=0.75) # plot percent daily volume grouped by 10 minute interval times\n",
    "ax1.set_ylim(0,10);\n",
    "plt.title('Intraday Volume Profile');\n",
    "ax1.set_ylabel('% of Day\\'s Volume in Bucket');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data = get_prices('usstock-free-1min', sids=AAPL, data_frequency='minute', start_date='2016-01-01', end_date='2018-01-02', fields='Volume')\n",
    "dat = data.loc['Volume'][AAPL]\n",
    "\n",
    "# Combine separate Date and Time in index into datetime\n",
    "dat.index = pd.to_datetime(dat.index.get_level_values('Date').astype(str) + ' ' + dat.index.get_level_values('Time'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_order_size(participation_rate, pct_ADV):\n",
    "    fill_start = dat['2017-10-02'].index[0] # start order at 9:31\n",
    "    ADV20 = int(dat.resample(\"1d\").sum()[-20:].mean()) # calculate 20 day ADV\n",
    "    order_size = int(pct_ADV * ADV20)\n",
    "    \n",
    "    try :\n",
    "        ftime = dat['2017-10-02'][(order_size * 1.0 / participation_rate)<=dat['2017-10-02'].cumsum().values].index[0]\n",
    "    except: \n",
    "        ftime = dat['2017-10-02'].index[-1] # set fill time to 4p \n",
    "    fill_time = max(1,int((ftime - fill_start).total_seconds()/60.0))\n",
    "    return fill_time\n",
    "\n",
    "def create_plots(participation_rate, ax):\n",
    "    df_pr = pd.DataFrame(data=np.linspace(0.0,0.1,100), columns = ['adv'] ) # create dataframe with intervals of ADV\n",
    "    df_pr['pr'] = participation_rate # add participation rate column\n",
    "\n",
    "    df_pr['fill_time'] = df_pr.apply(lambda row: relative_order_size(row['pr'],row['adv']), axis = 1) # get fill time\n",
    "\n",
    "    ax.plot(df_pr['adv'],df_pr['fill_time'], label=participation_rate) # generate plot line with ADV and fill time\n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "for i in [0.01,0.02,0.03,0.04,0.05,0.06,0.07]: # for participation rate values\n",
    "    create_plots(i,ax) # generate plot line\n",
    "    \n",
    "plt.ylabel('Time from Open (minutes)')\n",
    "plt.xlabel('Percent Average Daily Volume')\n",
    "plt.title('Trade Completion Time as Function of Relative Order Size and Participation Rate')\n",
    "plt.xlim(0.,0.04)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = get_prices('usstock-free-1min', sids=AAPL, data_frequency='minute', start_date='2016-01-01', end_date='2016-07-01')\n",
    "df = data[AAPL].unstack(level='Field')\n",
    "\n",
    "# Combine separate Date and Time in index into datetime\n",
    "df.index = pd.to_datetime(df.index.get_level_values('Date').astype(str) + ' ' + df.index.get_level_values('Time'))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def gkyz_var(open, high, low, close, close_tm1): # Garman Klass Yang Zhang extension OHLC volatility estimate\n",
    "    return np.log(open/close_tm1)**2 + 0.5*(np.log(high/low)**2) \\\n",
    "        - (2*np.log(2)-1)*(np.log(close/open)**2)\n",
    "    \n",
    "def historical_vol(close_ret, mean_ret): # close to close volatility estimate\n",
    "    return np.sqrt(np.sum((close_ret-mean_ret)**2)/390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['min_of_day'] = (df.index.hour-9)*60 + (df.index.minute-30) # calculate minute from the open\n",
    "df['time'] = df.index.time # add column time index\n",
    "df['day'] = df.index.date # add column date index\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['close_tm1'] = df.groupby('day')['Close'].shift(1)  # shift close value down one row\n",
    "df.close_tm1 = df.close_tm1.fillna(df.Open)\n",
    "df['min_close_ret'] = np.log( df['Close'] /df['close_tm1']) # log of close to close\n",
    "close_returns = df.groupby('day')['min_close_ret'].mean() # daily mean of log of close to close\n",
    "new_df = df.merge(pd.DataFrame(close_returns), left_on ='day', right_index = True)\n",
    "# handle when index goes from 16:00 to 9:31:\n",
    "\n",
    "new_df['variance'] = new_df.apply(\n",
    "    lambda row: historical_vol(row.min_close_ret_x, row.min_close_ret_y),\n",
    "    axis=1)\n",
    "\n",
    "new_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_daysum = pd.DataFrame(new_df['variance'].resample('d').sum()) # get sum of intraday variances daily\n",
    "df_daysum.columns = ['day_variance']\n",
    "df_daysum['day'] = df_daysum.index.date\n",
    "df_daysum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "conversion = {'variance':'sum', 'min_of_day':'last', 'time':'last'}\n",
    "df = new_df.resample('10t', closed='right').apply(conversion)\n",
    "df['day'] = df.index.date\n",
    "df['time'] = df.index.time\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = df.merge(df_daysum, how='left', on='day') # merge daily and intraday volatilty dataframes\n",
    "df['interval_pct'] = df['variance'] / df['day_variance'] # calculate percent of days volatility for each row\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(df.min_of_day, df.interval_pct)\n",
    "plt.xlim(0,400)\n",
    "plt.ylim(0,)\n",
    "plt.xlabel('Time from Open (minutes)')\n",
    "plt.ylabel('Interval Contribution of Daily Volatility')\n",
    "plt.title('Probabilty Distribution of Daily Volatility ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "grouped = df.groupby(df.min_of_day)\n",
    "grouped = df.groupby(df.time) # groupby time\n",
    "m = grouped.median() # get median\n",
    "x = m.index\n",
    "y = m['interval_pct'][datetime.time(9,30):datetime.time(15,59)]\n",
    "\n",
    "(100*y).plot(kind='bar', alpha=0.75);# plot interval percent of median daily volatility \n",
    "plt.title('Intraday Volatility Profile')\n",
    "ax1.set_ylabel('% of Day\\'s Variance in Bucket');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_spread(time, vol, mcap = 1.67 * 10 ** 10, adv = 84.5, px = 91.0159):\n",
    "    time_bins = np.array([0.0, 960.0, 2760.0, 5460.0, 21660.0]) #seconds from market open\n",
    "    time_coefs = pd.Series([0.0, -0.289, -0.487, -0.685, -0.952])\n",
    "    \n",
    "    vol_bins = np.array([0.0, .1, .15, .2, .3, .4])\n",
    "    vol_coefs = pd.Series([0.0, 0.251, 0.426, 0.542, 0.642, 0.812])\n",
    "    \n",
    "    mcap_bins = np.array([0.0, 2.0, 5.0, 10.0, 25.0, 50.0]) * 10 ** 9\n",
    "    mcap_coefs = pd.Series([0.291, 0.305, 0.0, -0.161, -0.287, -0.499])\n",
    "    \n",
    "    adv_bins = np.array([0.0, 50.0, 100.0, 150.0, 250.0, 500.0]) * 10 ** 6\n",
    "    adv_coefs = pd.Series([0.303, 0.0, -0.054, -0.109, -0.242, -0.454])\n",
    "    \n",
    "    px_bins = np.array([0.0, 28.0, 45.0, 62.0, 82.0, 132.0])\n",
    "    px_coefs = pd.Series([-0.077, -0.187, -0.272, -0.186, 0.0, 0.380])\n",
    "    \n",
    "    return np.exp(1.736 +\\\n",
    "                  time_coefs[np.digitize(time, time_bins) - 1] +\\\n",
    "                  vol_coefs[np.digitize(vol, vol_bins) - 1] +\\\n",
    "                  mcap_coefs[np.digitize(mcap, mcap_bins) - 1] +\\\n",
    "                  adv_coefs[np.digitize(adv, adv_bins) - 1] +\\\n",
    "                  px_coefs[np.digitize(px, px_bins) - 1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "t = 10 * 60\n",
    "vlty = 0.188\n",
    "mcap = 1.67 * 10 ** 10\n",
    "adv = 84.5 *10\n",
    "price = 91.0159 \n",
    "print(model_spread(t, vlty, mcap, adv, price), 'bps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,390*60) # seconds from open shape (50,)\n",
    "y = np.linspace(.01,.7) # volatility shape(50,)\n",
    "mcap = 1.67 * 10 ** 10\n",
    "adv = 84.5\n",
    "px = 91.0159\n",
    "\n",
    "\n",
    "vlty_coefs = pd.Series([0.0, 0.251, 0.426, 0.542, 0.642, 0.812])\n",
    "vlty_bins = np.array([0.0, .1, .15, .2, .3, .4])\n",
    "time_bins = np.array([0.0, 960.0, 2760.0, 5460.0, 21660.0]) #seconds from market open\n",
    "time_coefs = pd.Series([0.0, -0.289, -0.487, -0.685, -0.952])\n",
    "mcap_bins = np.array([0.0, 2.0, 5.0, 10.0, 25.0, 50.0]) * 10 ** 9\n",
    "mcap_coefs = pd.Series([0.291, 0.305, 0.0, -0.161, -0.287, -0.499])\n",
    "adv_bins = np.array([0.0, 50.0, 100.0, 150.0, 250.0, 500.0]) * 10 ** 6\n",
    "adv_coefs = pd.Series([0.303, 0.0, -0.054, -0.109, -0.242, -0.454])\n",
    "px_bins = np.array([0.0, 28.0, 45.0, 62.0, 82.0, 132.0])\n",
    "px_coefs = pd.Series([-0.077, -0.187, -0.272, -0.186, 0.0, 0.380])\n",
    "# shape (1, 50)\n",
    "time_contrib = np.take(time_coefs, np.digitize(x, time_bins) - 1).values.reshape((1, len(x)))\n",
    "# shape (50, 1)\n",
    "vlty_contrib = np.take(vlty_coefs, np.digitize(y, vlty_bins) - 1).values.reshape((len(y), 1))\n",
    "# scalar\n",
    "mcap_contrib = mcap_coefs[np.digitize((mcap,), mcap_bins)[0] - 1]\n",
    "# scalar\n",
    "adv_contrib = adv_coefs[np.digitize((adv,), adv_bins)[0] - 1]\n",
    "# scalar\n",
    "px_contrib = px_coefs[np.digitize((px,), px_bins)[0] - 1]\n",
    "\n",
    "z_scalar_contrib = 1.736 + mcap_contrib + adv_contrib + px_contrib\n",
    "\n",
    "\n",
    "Z = np.exp(z_scalar_contrib + time_contrib + vlty_contrib)\n",
    "\n",
    "cmap=plt.get_cmap('jet')\n",
    "X, Y = np.meshgrid(x,y)\n",
    "CS = plt.contour(X/60,Y,Z, linewidths=3, cmap=cmap, alpha=0.8);\n",
    "plt.clabel(CS)\n",
    "plt.xlabel('Time from the Open (Minutes)')\n",
    "plt.ylabel('Volatility')\n",
    "plt.title('Spreads for varying Volatility and Trading Times (mcap = 16.7B, px = 91, adv = 84.5M)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def perm_impact(pct_adv, annual_vol_pct = 0.25, inv_turnover = 200):\n",
    "    gamma = 0.314\n",
    "    return 10000 * gamma * (annual_vol_pct / 16) * pct_adv * (inv_turnover)**0.25\n",
    "\n",
    "def temp_impact(pct_adv, minutes, annual_vol_pct = 0.25, minutes_in_day = 60*6.5):\n",
    "    eta = 0.142\n",
    "    day_frac = minutes / minutes_in_day\n",
    "    return 10000 * eta * (annual_vol_pct / 16) * abs(pct_adv/day_frac)**0.6\n",
    "\n",
    "def tc_bps(pct_adv, minutes, annual_vol_pct = 0.25, inv_turnover = 200, minutes_in_day = 60*6.5):\n",
    "    perm = perm_impact(pct_adv, annual_vol_pct=annual_vol_pct, inv_turnover=inv_turnover)\n",
    "    temp = temp_impact(pct_adv, minutes, annual_vol_pct=annual_vol_pct, minutes_in_day=minutes_in_day)\n",
    "    return 0.5 * perm + temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print('Cost to trade Fast (First 40 mins):', round(tc_bps(pct_adv=0.1, annual_vol_pct=16*0.0157, inv_turnover=263, minutes=0.1*60*6.5),2), 'bps')\n",
    "print('Cost to trade Medium (First 90 mins):', round(tc_bps(pct_adv=0.1, annual_vol_pct=16*0.0157, inv_turnover=263, minutes=0.2*60*6.5),2), 'bps' )\n",
    "print('Cost to trade Slow by Noon:', round(tc_bps(pct_adv=0.1, annual_vol_pct=16*0.0157, inv_turnover=263, minutes=0.5*60*6.5),2), 'bps')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trading 0.50% of ADV of a stock with a daily vol of 1.57% and we plan to do this over 30 minutes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(round(tc_bps(pct_adv=0.005, minutes=30, annual_vol_pct=16*0.0157),2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we wanted to trade \\$2M notional of Facebook, and we are going to send the trade to an execution algo (e.g., VWAP) to be sliced over 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trade_notional = 2000000 # 2M notional\n",
    "stock_price = 110.89 # dollars per share\n",
    "shares_to_trade = trade_notional/stock_price\n",
    "stock_adv_shares = 30e6 # 30 M\n",
    "stock_shares_outstanding = 275e9/110.89\n",
    "\n",
    "expected_tc = tc_bps(shares_to_trade/stock_adv_shares, minutes=15, annual_vol_pct=0.22)\n",
    "print(\"Expected tc in bps: %0.2f\" % expected_tc)\n",
    "print(\"Expected tc in $ per share: %0.2f\" % (expected_tc*stock_price / 10000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to motivate some intuition, at the total expected cost varies as a function of how much % ADV we want to trade in 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0.0001,0.03)\n",
    "plt.plot(x*100,tc_bps(x,30,0.25), label=r\"$\\sigma$ = 25%\");\n",
    "plt.plot(x*100,tc_bps(x,30,0.40), label=r\"$\\sigma$ = 40%\");\n",
    "plt.ylabel('tcost in bps')\n",
    "plt.xlabel('Trade as % of ADV')\n",
    "plt.title(r'tcost in Basis Points of Trade Value; $\\sigma$ = 25% and 40%; time = 15 minutes');\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's look a tcost as a function of trading time and % ADV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0.001,0.03)\n",
    "y = np.linspace(5,30)\n",
    "X, Y = np.meshgrid(x,y)\n",
    "Z = tc_bps(X,Y,0.20)\n",
    "levels = np.linspace(0.0, 60, 30)\n",
    "cmap=plt.get_cmap('Reds')\n",
    "cmap=plt.get_cmap('hot')\n",
    "cmap=plt.get_cmap('jet')\n",
    "\n",
    "plt.subplot(1,2,1);\n",
    "CS = plt.contour(X*100, Y, Z, levels, linewidths=3, cmap=cmap, alpha=0.55);\n",
    "plt.clabel(CS);\n",
    "plt.ylabel('Trading Time in Minutes');\n",
    "plt.xlabel('Trade as % of ADV');\n",
    "plt.title(r'tcost in Basis Points of Trade Value; $\\sigma$ = 20%');\n",
    "\n",
    "plt.subplot(1,2,2);\n",
    "Z = tc_bps(X,Y,0.40)\n",
    "CS = plt.contour(X*100, Y, Z, levels, linewidths=3, cmap=cmap, alpha=0.55);\n",
    "plt.clabel(CS);\n",
    "plt.ylabel('Trading Time in Minutes');\n",
    "plt.xlabel('Trade as % of ADV');\n",
    "plt.title(r'tcost in Basis Points of Trade Value; $\\sigma$ = 40%');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we might want to get some intuition as to if we wanted to limit our cost, how does the trading time vary versus % of ADV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0.001,0.03) # % ADV\n",
    "y = np.linspace(1,60*6.5)   # time to trade\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "levels = np.linspace(0.0, 390, 20)\n",
    "cmap=plt.get_cmap('Reds')\n",
    "cmap=plt.get_cmap('hot')\n",
    "cmap=plt.get_cmap('jet')\n",
    "\n",
    "plt.subplot(1,2,1);\n",
    "\n",
    "Z = tc_bps(X,Y,0.20)\n",
    "plt.contourf(X*100, Z, Y, levels, cmap=cmap, alpha=0.55);\n",
    "plt.title(r'Trading Time in Minutes; $\\sigma$ = 20%');\n",
    "plt.xlabel('Trade as % of ADV');\n",
    "plt.ylabel('tcost in Basis Points of Trade Value');\n",
    "plt.ylim(5,20)\n",
    "plt.colorbar();\n",
    "\n",
    "plt.subplot(1,2,2);\n",
    "Z = tc_bps(X,Y,0.40)\n",
    "plt.contourf(X*100, Z, Y, levels, cmap=cmap, alpha=0.55);\n",
    "plt.title(r'Trading Time in Minutes; $\\sigma$ = 40%');\n",
    "plt.xlabel('Trade as % of ADV');\n",
    "plt.ylabel('tcost in Basis Points of Trade Value');\n",
    "plt.ylim(5,20);\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "minutes = 30\n",
    "\n",
    "x = np.linspace(0.0001,0.03)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "f.subplots_adjust(hspace=0.15)\n",
    "    \n",
    "p = 0.5*perm_impact(x,0.20)\n",
    "t = tc_bps(x,minutes,0.20)\n",
    "ax1.fill_between(x*100, p, t, color='b', alpha=0.33);\n",
    "ax1.fill_between(x*100, 0, p, color='k', alpha=0.66);\n",
    "ax1.set_ylabel('tcost in bps')\n",
    "ax1.set_xlabel('Trade as % of ADV')\n",
    "ax1.set_title(r'tcost in bps of Trade Value; $\\sigma$ = 20%; time = 15 minutes');\n",
    "\n",
    "p = 0.5*perm_impact(x, 0.40)\n",
    "t = tc_bps(x,minutes, 0.40)\n",
    "ax2.fill_between(x*100, p, t, color='b', alpha=0.33);\n",
    "ax2.fill_between(x*100, 0, p, color='k', alpha=0.66);\n",
    "\n",
    "plt.xlabel('Trade as % of ADV')\n",
    "plt.title(r'tcost in bps of Trade Value; $\\sigma$ = 40%; time = 15 minutes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def kissell(adv, annual_vol, interval_vol, order_size):\n",
    "    b1, a1, a2, a3, a4 = 0.9, 750., 0.2, 0.9, 0.5\n",
    "    i_star = a1 * ((order_size/adv)**a2) * annual_vol**a3\n",
    "    PoV = order_size/(order_size + adv)\n",
    "    return b1 * i_star * PoV**a4 + (1 - b1) * i_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(kissell(adv=5*10**6, annual_vol=0.2, interval_vol=adv * 0.06, order_size=0.01 * adv ), 'bps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0.0001,0.1)\n",
    "plt.plot(x,kissell(5*10**6,0.1, 2000*10**3, x*2000*10**3), label=r\"$\\sigma$ = 10%\");\n",
    "plt.plot(x,kissell(5*10**6,0.25, 2000*10**3, x*2000*10**3), label=r\"$\\sigma$ = 25%\");\n",
    "plt.ylabel('tcost in bps')\n",
    "plt.xlabel('Trade as % of ADV')\n",
    "plt.title(r'tcost in Basis Points of Trade Value; $\\sigma$ = 25% and 40%; time = 15 minutes');\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
